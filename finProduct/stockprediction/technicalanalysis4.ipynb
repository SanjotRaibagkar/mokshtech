{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Prgs\\Code\\mokshtech\\Fin_Product\n",
      "importing Jupyter notebook from C:\\Prgs\\Code\\mokshtech\\Fin_Product\\utility\\Load_Csv.ipynb\n",
      "C:\\Prgs\\Code\\mokshtech\\Fin_Product\\stockprediction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import import_ipynb\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import talib\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "\n",
    "'''to be modified and shift into property files'''\n",
    "currentpath=os.getcwd()\n",
    "dbpath=os.path.join(currentpath,\"..\",'database')\n",
    "stockcsv=os.path.join(dbpath,'stockpath.csv')\n",
    "stocktest=os.path.join(dbpath,'stocktest.csv')\n",
    "\n",
    "featurescsv=os.path.join(dbpath,'features.csv')\n",
    "featuresdata=os.path.join(dbpath,'featuresdata.csv')\n",
    "\n",
    "\n",
    "\n",
    "#to import Load_Csv file from another directory. this style is for jupyter notebook\n",
    "                \n",
    "%cd ..\n",
    "from utility import Load_Csv as lcsv\n",
    "%cd stockprediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ta(lcsv.Load_csv):\n",
    "    '''this class contains functions fto predict label with the help of technical indicators'''\n",
    "    \n",
    "    def __init__(self,filename=stockcsv):\n",
    "        self.filename=filename\n",
    "    \n",
    "\n",
    "    def loadcsv(self):\n",
    "        '''load 'Date','Close', 'Volume' data from databse and return dataframe\n",
    "        '''\n",
    "        \n",
    "        self.dataset=self.LoadData(self.filename).loc[:, ['Date','Close', 'Volume','Open']]\n",
    "        self.dataset['Date'] = pd.to_datetime(self.dataset['Date'])\n",
    "        return self.dataset\n",
    "    \n",
    "\n",
    "    def loadfeaturesdata(self,x):\n",
    "        '''load features detailed data from databse'''\n",
    "        self.featuresdata=self.LoadfeaData(featuresdata)\n",
    "        self.featuresdata.index=self.featuresdata[0]\n",
    "        #self.featuresdata=self.featuresdata.loc[x]\n",
    "        return list(self.featuresdata.loc[x,1:])\n",
    "    \n",
    "    \n",
    "    def ti_Combinations(self):\n",
    "        '''takes input as list of list and  gives output as comninations '''\n",
    "        \n",
    "        #print(\"ti_Combinations\")\n",
    "\n",
    "        self.paneldict={}\n",
    "        def comb_r(row):\n",
    "            \n",
    "            #print(self.dataset)\n",
    "            #print('row',row)\n",
    "            comb_dataset=self.dataset.copy(deep=True)\n",
    "            for i in row:\n",
    "                #print('i',i)\n",
    "                comb_dataset['MA'+str(i)]=self.tdf['MA'+str(i)]\n",
    "                #print('comb_dataset',comb_dataset)\n",
    "            #print('c',comb_dataset)    #To print dataset with all combinations of MA\n",
    "            \n",
    "            #print('self.paneldict',self.paneldict)\n",
    "            self.paneldict[row]=comb_dataset.copy(deep=True)\n",
    "            #print('self.paneldict2',self.paneldict)\n",
    "\n",
    "\n",
    "        try:\n",
    "            a=self.tidict['MA']\n",
    "            #print('combinations_input',a)\n",
    "            #[[10],[50],[60-64]]\n",
    "            comb_df=pd.Series(list(itertools.product(*a)))##get combinatons \n",
    "            #print('comb_df',comb_df)\n",
    "            comb_df.apply(comb_r)\n",
    "            panel_dataset=pd.Panel(self.paneldict)\n",
    "         \n",
    "            '''\n",
    "            ### Error: Panel is not working here . \n",
    "            On printing panel it is printing merge of all unique columns for each dataframe.\n",
    "            \n",
    "            \n",
    "            #print(item for item in panel_dataset.items])  # to print item name of panel\n",
    "            #print('(2, 4, 60)',panel_dataset[(2, 4, 60)])\n",
    "            \n",
    "            '''\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            print('e2',e)         \n",
    "       \n",
    "        \n",
    "    def loadfeatures(self):\n",
    "        '''load feature label data from databse\n",
    "        '''\n",
    "        self.featurestilist=[]\n",
    "        self.misc=[]\n",
    "        self.label=[]\n",
    "        self.tilist=dir(talib)\n",
    "        self.featuredict={}\n",
    "        self.tidict={}\n",
    "        self.features=self.LoadfeaData(featurescsv)\n",
    "\n",
    "         \n",
    "        def func(value,args):\n",
    "           \n",
    "\n",
    "            if str(value).find(\"-\")>-1:   #tocheck if range is given \n",
    "                a,b=value.split(\"-\")\n",
    "                a=int(a)\n",
    "                b=int(b)\n",
    "\n",
    "                self.featuredict[args].extend(list(range(a,b)))   #if range is given then replace it by list\n",
    "                self.tidict[args].append(list(range(a,b))) \n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    var=str(args)+'-'+str(int(value))              #togenerate name like MA-1,MA-2  \n",
    "\n",
    "                    self.featuredict[args].extend(self.loadfeaturesdata(var))\n",
    "                    \n",
    "                    self.tidict[args].append(self.loadfeaturesdata(var))\n",
    "                except Exception as e:\n",
    "                    print('e1',e)    \n",
    "        \n",
    "        \n",
    "        def funr(row):\n",
    "            r_len=len(row)\n",
    "            ti=row[0]\n",
    "            rowdf=pd.Series(row[1:])\n",
    "            \n",
    "                     \n",
    "            if ti in self.tilist:\n",
    "                self.featuredict[ti]=[]\n",
    "                self.tidict[ti]=[]\n",
    "                self.featurestilist.append(ti)\n",
    "                \n",
    "                rowdf.apply(func,args=(ti,))    #Vectorize function over each element\n",
    "                \n",
    "            elif ti=='label':\n",
    "                self.label.append(row[1])\n",
    "            else:\n",
    "                self.misc.append(row)\n",
    "    \n",
    "                \n",
    "                                                 #vectorize approach to speed up process        \n",
    "        self.features.apply(funr, axis=1)\n",
    "        #print(self.featuredict)                  #To be removed after development\n",
    "        #print(self.features)\n",
    "        #print(\"end\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        #return(self.featurestilist,self.label,self.misc,self.MA_comb)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_MA(self,x):\n",
    "        malist=self.featuredict['MA']\n",
    "        for i in malist:\n",
    "            if ('MA'+str(i)) in self.tdf:\n",
    "                continue\n",
    "            else:          \n",
    "                self.tdf['MA'+str(i)]=talib.SMA(self.dataset[x],i)\n",
    "        return(self.tdf)\n",
    "        \n",
    "    def get_RSI(self,x):\n",
    "        rsilist=self.featuredict['RSI']\n",
    "        for i in rsilist:\n",
    "            if ('RSI'+str(i)) in self.tdf:\n",
    "                continue\n",
    "            else:\n",
    "                self.dataset['RSI'+str(i)]=talib.RSI(self.dataset[x],i)\n",
    "        return(self.dataset)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_technical_indi(self):\n",
    "        \n",
    "        self.tdf=self.LoadData(stockcsv).loc[:, ['Close']]\n",
    "        for i in self.featurestilist:\n",
    "            if i=='MA':\n",
    "                self.get_MA('Close')\n",
    "            if i=='RSI':\n",
    "                self.get_RSI('Close')\n",
    "                \n",
    "                \n",
    "    def get_return(self):\n",
    "        self.dataset['Daily_Return'] = self.dataset['Close'].pct_change()\n",
    "        \n",
    "        \n",
    "    def get_label(self):\n",
    "        print(\"start technical analysis and  Calculate technical indicators\")\n",
    "        if self.label[0]=='return':\n",
    "            self.get_return()\n",
    "        #print(self.dataset)\n",
    "        #print(self.tdf)\n",
    "        #print(self.tidict)\n",
    "       \n",
    "    def get_panel_data(self):\n",
    "        self.loadcsv()\n",
    "        self.loadfeatures()\n",
    "        self.get_technical_indi()\n",
    "        self.get_label()\n",
    "        self.ti_Combinations()\n",
    "        return(self.paneldict)\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importing the Keras libraries and packages to build RNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class rnn_prediction(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        '''To be inclueded in features file or property file'''\n",
    "        \n",
    "        self.test_size=0.2 #b.test_size  #to split dataset in training and testing part.   \n",
    "        self.LSTM_units=50\n",
    "        self.LSTM_unit_increment=30\n",
    "        self.dropoutunit=0.2\n",
    "        self.layer=4\n",
    "        \n",
    "        \n",
    "     \n",
    "    def data_preprocessing(self):\n",
    "        '''1. feature scaling to normalize data and fit between 0 and 1\n",
    "        2. Creating data sctructure for test and training   \n",
    "                \n",
    "        '''\n",
    "        #feature scaling \n",
    "        sc = MinMaxScaler(feature_range = (0, 1))\n",
    "        df_scaled = sc.fit_transform(self.df)\n",
    "        y_scaled = sc.fit_transform(self.y)\n",
    "        \n",
    "        #Creating data sctructure for test and training\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df_scaled, y_scaled, test_size=self.test_size)\n",
    "        X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "        \n",
    "        print('Before reshaping','X_train :{0}, y_train :{1} ,X_test :{2} ,y_test :{3}'.format(X_train.shape, y_train.shape,X_test.shape, y_test.shape))\n",
    "        \n",
    "        #Reshape xtrain and xtest to fit in lstm model\n",
    "        \n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "        \n",
    "        #print('After reshaping','X_train :{0}, y_train :{1} ,X_test :{2} ,y_test :{3}'.format(X_train.shape, y_train.shape,X_test.shape, y_test.shape))\n",
    "\n",
    "        #return(X_train, X_test, y_train, y_test)\n",
    "        \n",
    "    #def model_building(self):\n",
    "           \n",
    "        #X_train, X_test, y_train, y_test=self.data_preprocessing()\n",
    "        \n",
    "        print('After reshaping','X_train :{0}, y_train :{1} ,X_test :{2} ,y_test :{3}'.format(X_train.shape, y_train.shape,X_test.shape, y_test.shape))\n",
    "\n",
    "        \n",
    "        LSTM_units = self.LSTM_units\n",
    "        LSTM_unit_increment = self.LSTM_unit_increment\n",
    "        dropoutunit = self.dropoutunit\n",
    "        \n",
    "        # Initialising the RNN\n",
    "        regressor = Sequential()\n",
    "\n",
    "        # Adding the first LSTM layer and some Dropout regularisation\n",
    "        regressor.add(LSTM(units = LSTM_units, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "        regressor.add(Dropout(dropoutunit))\n",
    "        \n",
    "        '''\n",
    "        for i in range(self.layer):\n",
    "            LSTM_units=LSTM_units+LSTM_unit_increment\n",
    "            regressor.add(LSTM(units = LSTM_units, return_sequences = True))\n",
    "            regressor.add(Dropout(dropoutunit))\n",
    "            \n",
    "        '''\n",
    "        #layer 2\n",
    "        LSTM_units=LSTM_units+LSTM_unit_increment\n",
    "        regressor.add(LSTM(units = LSTM_units, return_sequences = True))\n",
    "        regressor.add(Dropout(dropoutunit))\n",
    "        \n",
    "        #layer 3\n",
    "        LSTM_units=LSTM_units+LSTM_unit_increment\n",
    "        regressor.add(LSTM(units = LSTM_units, return_sequences = True))\n",
    "        regressor.add(Dropout(dropoutunit))\n",
    "        \n",
    "        #Layer 4\n",
    "        LSTM_units=LSTM_units+LSTM_unit_increment\n",
    "        regressor.add(LSTM(units = LSTM_units, return_sequences = True))\n",
    "        regressor.add(Dropout(dropoutunit))\n",
    "        \n",
    "        \n",
    "            \n",
    "        # Adding the output layer\n",
    "        regressor.add(Dense(units = 1))\n",
    "\n",
    "        # Compiling the RNN\n",
    "        regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "        # Fitting the RNN to the Training set\n",
    "        print(X_train.shape,y_train.shape)\n",
    "        \n",
    "        try:\n",
    "\n",
    "            regressor.fit(X_train, y_train, epochs = 20, batch_size = 200)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        finally:\n",
    "            #temorary adding to self object.\n",
    "            self.regressor=regressor\n",
    "            self.X_test=X_test\n",
    "            self.sc=sc\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def startrnn(self):\n",
    "        \n",
    "        b=ta()\n",
    "        train_paneldict=b.get_panel_data()\n",
    "        \n",
    "        itemlist=[items for items in train_paneldict]\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        for item in itemlist:\n",
    "\n",
    "\n",
    "            dataset_train_a=train_paneldict[item]\n",
    "            #print('item',item,dataset_train_a)\n",
    "            print('label',b.label[0])\n",
    "            self.df = dataset_train_a.iloc[61:, 2:].values\n",
    "            self.y = dataset_train_a.iloc[61:, 1:2].values #Close  # implement method to get label from file.\n",
    "            self.data_preprocessing()\n",
    "            break\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        item=(2,4,60)\n",
    "        dataset_train_a=train_paneldict[item]\n",
    "        #print(dataset_train_a)\n",
    "        #print('item',item,dataset_train_a)\n",
    "        print('label',b.label[0])\n",
    "        self.df = dataset_train_a.iloc[61:, 2:].values\n",
    "        self.y = dataset_train_a.iloc[61:, 1:2].values #Close  # implement method to get label from file.\n",
    "        self.data_preprocessing()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1 cannot convert float NaN to integer\n",
      "start technical analysis and  Calculate technical indicators\n",
      "label return\n",
      "Before reshaping X_train :(807, 8), y_train :(807, 1) ,X_test :(202, 8) ,y_test :(202, 1)\n",
      "After reshaping X_train :(807, 8, 1), y_train :(807, 1) ,X_test :(202, 8, 1) ,y_test :(202, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:183: DeprecationWarning: \n",
      "Panel is deprecated and will be removed in a future version.\n",
      "The recommended way to represent these types of 3-dimensional data are with a MultiIndex on a DataFrame, via the Panel.to_frame() method\n",
      "Alternatively, you can use the xarray package http://xarray.pydata.org/en/stable/.\n",
      "Pandas provides a `.to_xarray()` method to help automate this conversion.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(807, 8, 1) (807, 1)\n",
      "Error when checking target: expected dense_4 to have 3 dimensions, but got array with shape (807, 1)\n"
     ]
    }
   ],
   "source": [
    "b=rnn_prediction()\n",
    "b.startrnn()\n",
    "regressor=b.regressor\n",
    "X_test=b.X_test\n",
    "sc=b.sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a84b6d1775d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mpredicted_stock_price\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mpredicted_stock_price\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_stock_price\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'scale_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[1;32m--> 451\u001b[1;33m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "# Part 3 - Making the predictions and visualising the results\n",
    "\n",
    "\n",
    "#real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "\n",
    "'''\n",
    "dataset_total = pd.concat((dataset_train_a['Close'], dataset_test['Close']), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(60, 133):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "y_test = sc.inverse_transform(y_test)\n",
    "\n",
    "\n",
    "\n",
    "print('p',predicted_stock_price[0:5])\n",
    "print('r',y_test[0:5])\n",
    "\n",
    "predicted_stock_price=predicted_stock_price[0:60]\n",
    "y_test=y_test[0:60]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the results\n",
    "width = 15\n",
    "height = 10\n",
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "\n",
    "plt.plot(y_test, color = 'red', label = 'Real Nifty  Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Nifty Stock Price')\n",
    "plt.title('Nifty Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Nifty Stock Price')\n",
    "plt.legend()\n",
    "plt.grid(color='b', linestyle='--', linewidth=1)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score:\", regressor.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsepickel1 = open(\"nsepickel1\",'wb')\n",
    "pickle.dump(regressor , nsepickel1)\n",
    "nsepickel1.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
