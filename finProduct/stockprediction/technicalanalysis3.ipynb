{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import import_ipynb\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import talib\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "\n",
    "'''to be modified and shift into property files'''\n",
    "currentpath=os.getcwd()\n",
    "dbpath=os.path.join(currentpath,\"..\",'database')\n",
    "stockcsv=os.path.join(dbpath,'stockpath.csv')\n",
    "stocktest=os.path.join(dbpath,'stocktest.csv')\n",
    "\n",
    "featurescsv=os.path.join(dbpath,'features.csv')\n",
    "featuresdata=os.path.join(dbpath,'featuresdata.csv')\n",
    "\n",
    "\n",
    "\n",
    "#to import Load_Csv file from another directory. this style is for jupyter notebook\n",
    "                \n",
    "%cd ..\n",
    "from utility import Load_Csv as lcsv\n",
    "%cd stockprediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ta(lcsv.Load_csv):\n",
    "    '''this class contains functions fto predict label with the help of technical indicators'''\n",
    "    \n",
    "    def __init__(self,filename=stockcsv):\n",
    "        self.filename=filename\n",
    "    \n",
    "\n",
    "    def loadcsv(self):\n",
    "        '''load 'Date','Close', 'Volume' data from databse and return dataframe\n",
    "        '''\n",
    "        \n",
    "        self.dataset=self.LoadData(self.filename).loc[:, ['Date','Close', 'Volume','Open']]\n",
    "        self.dataset['Date'] = pd.to_datetime(self.dataset['Date'])\n",
    "        return self.dataset\n",
    "    \n",
    "\n",
    "    def loadfeaturesdata(self,x):\n",
    "        '''load features detailed data from databse'''\n",
    "        self.featuresdata=self.LoadfeaData(featuresdata)\n",
    "        self.featuresdata.index=self.featuresdata[0]\n",
    "        #self.featuresdata=self.featuresdata.loc[x]\n",
    "        return list(self.featuresdata.loc[x,1:])\n",
    "    \n",
    "    \n",
    "    def ti_Combinations(self):\n",
    "        '''takes input as list of list and  gives output as comninations '''\n",
    "        \n",
    "        #print(\"ti_Combinations\")\n",
    "\n",
    "        self.paneldict={}\n",
    "        def comb_r(row):\n",
    "            \n",
    "            #print(self.dataset)\n",
    "            #print('row',row)\n",
    "            comb_dataset=self.dataset.copy(deep=True)\n",
    "            for i in row:\n",
    "                #print('i',i)\n",
    "                comb_dataset['MA'+str(i)]=self.tdf['MA'+str(i)]\n",
    "                #print('comb_dataset',comb_dataset)\n",
    "            #print('c',comb_dataset)    #To print dataset with all combinations of MA\n",
    "            \n",
    "            #print('self.paneldict',self.paneldict)\n",
    "            self.paneldict[row]=comb_dataset.copy(deep=True)\n",
    "            #print('self.paneldict2',self.paneldict)\n",
    "\n",
    "\n",
    "        try:\n",
    "            a=self.tidict['MA']\n",
    "            #print('combinations_input',a)\n",
    "            #[[10],[50],[60-64]]\n",
    "            comb_df=pd.Series(list(itertools.product(*a)))##get combinatons \n",
    "            #print('comb_df',comb_df)\n",
    "            comb_df.apply(comb_r)\n",
    "            panel_dataset=pd.Panel(self.paneldict)\n",
    "         \n",
    "            '''\n",
    "            ### Error: Panel is not working here . \n",
    "            On printing panel it is printing merge of all unique columns for each dataframe.\n",
    "            \n",
    "            \n",
    "            #print(item for item in panel_dataset.items])  # to print item name of panel\n",
    "            #print('(2, 4, 60)',panel_dataset[(2, 4, 60)])\n",
    "            \n",
    "            '''\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            print('e2',e)         \n",
    "       \n",
    "        \n",
    "    def loadfeatures(self):\n",
    "        '''load feature label data from databse\n",
    "        '''\n",
    "        self.featurestilist=[]\n",
    "        self.misc=[]\n",
    "        self.label=[]\n",
    "        self.tilist=dir(talib)\n",
    "        self.featuredict={}\n",
    "        self.tidict={}\n",
    "        self.features=self.LoadfeaData(featurescsv)\n",
    "\n",
    "         \n",
    "        def func(value,args):\n",
    "           \n",
    "\n",
    "            if str(value).find(\"-\")>-1:   #tocheck if range is given \n",
    "                a,b=value.split(\"-\")\n",
    "                a=int(a)\n",
    "                b=int(b)\n",
    "\n",
    "                self.featuredict[args].extend(list(range(a,b)))   #if range is given then replace it by list\n",
    "                self.tidict[args].append(list(range(a,b))) \n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    var=str(args)+'-'+str(int(value))              #togenerate name like MA-1,MA-2  \n",
    "\n",
    "                    self.featuredict[args].extend(self.loadfeaturesdata(var))\n",
    "                    \n",
    "                    self.tidict[args].append(self.loadfeaturesdata(var))\n",
    "                except Exception as e:\n",
    "                    print('e1',e)    \n",
    "        \n",
    "        \n",
    "        def funr(row):\n",
    "            r_len=len(row)\n",
    "            ti=row[0]\n",
    "            rowdf=pd.Series(row[1:])\n",
    "            \n",
    "                     \n",
    "            if ti in self.tilist:\n",
    "                self.featuredict[ti]=[]\n",
    "                self.tidict[ti]=[]\n",
    "                self.featurestilist.append(ti)\n",
    "                \n",
    "                rowdf.apply(func,args=(ti,))    #Vectorize function over each element\n",
    "                \n",
    "            elif ti=='label':\n",
    "                self.label.append(row[1])\n",
    "            else:\n",
    "                self.misc.append(row)\n",
    "    \n",
    "                \n",
    "                                                 #vectorize approach to speed up process        \n",
    "        self.features.apply(funr, axis=1)\n",
    "        #print(self.featuredict)                  #To be removed after development\n",
    "        #print(self.features)\n",
    "        #print(\"end\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        #return(self.featurestilist,self.label,self.misc,self.MA_comb)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_MA(self,x):\n",
    "        malist=self.featuredict['MA']\n",
    "        for i in malist:\n",
    "            if ('MA'+str(i)) in self.tdf:\n",
    "                continue\n",
    "            else:          \n",
    "                self.tdf['MA'+str(i)]=talib.SMA(self.dataset[x],i)\n",
    "        return(self.tdf)\n",
    "        \n",
    "    def get_RSI(self,x):\n",
    "        rsilist=self.featuredict['RSI']\n",
    "        for i in rsilist:\n",
    "            if ('RSI'+str(i)) in self.tdf:\n",
    "                continue\n",
    "            else:\n",
    "                self.dataset['RSI'+str(i)]=talib.RSI(self.dataset[x],i)\n",
    "        return(self.dataset)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_technical_indi(self):\n",
    "        \n",
    "        self.tdf=self.LoadData(stockcsv).loc[:, ['Close']]\n",
    "        for i in self.featurestilist:\n",
    "            if i=='MA':\n",
    "                self.get_MA('Close')\n",
    "            if i=='RSI':\n",
    "                self.get_RSI('Close')\n",
    "                \n",
    "                \n",
    "    def get_return(self):\n",
    "        self.dataset['Daily_Return'] = self.dataset['Close'].pct_change()\n",
    "        \n",
    "        \n",
    "    def get_label(self):\n",
    "        print(\"start technical analysis and  Calculate technical indicators\")\n",
    "        if self.label[0]=='return':\n",
    "            self.get_return()\n",
    "        #print(self.dataset)\n",
    "        #print(self.tdf)\n",
    "        #print(self.tidict)\n",
    "       \n",
    "    def get_panel_data(self,arg):\n",
    "        self.loadcsv()\n",
    "        self.loadfeatures()\n",
    "        self.get_technical_indi()\n",
    "        self.get_label()\n",
    "        self.ti_Combinations()\n",
    "        print(arg)\n",
    "        return self.paneldict[arg]\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=ta()\n",
    "train_paneldict=b.get_panel_data((2,4,60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=0.2 #b.test_size  #to split dataset in training and testing part.   \n",
    "LSTM_units=50\n",
    "LSTM_unit_increment=30\n",
    "dropoutunit=0.2\n",
    "layer=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before reshaping X_train :(807, 8), y_train :(807, 1) ,X_test :(202, 8) ,y_test :(202, 1)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = train_paneldict.iloc[61:, 2:].values\n",
    "y = train_paneldict.iloc[61:, 1:2].values #Close  # implement method to get label from file.\n",
    "#feature scaling \n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "df_scaled = sc.fit_transform(df)\n",
    "y_scaled = sc.fit_transform(y)\n",
    "\n",
    "#Creating data sctructure for test and training\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_scaled, y_scaled, test_size=test_size)\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "\n",
    "print('Before reshaping','X_train :{0}, y_train :{1} ,X_test :{2} ,y_test :{3}'.format(X_train.shape, y_train.shape,X_test.shape, y_test.shape))\n",
    "\n",
    "#Reshape xtrain and xtest to fit in lstm model\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "#print('After reshaping','X_train :{0}, y_train :{1} ,X_test :{2} ,y_test :{3}'.format(X_train.shape, y_train.shape,X_test.shape, y_test.shape))\n",
    "\n",
    "#return(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Building the RNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 150, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 200))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "print(X_train.shape,y_train.shape)\n",
    "regressor.fit(X_train, y_train, epochs = 20, batch_size = 200)\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making the predictions and visualising the results\n",
    "\n",
    "\n",
    "#real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "\n",
    "'''\n",
    "dataset_total = pd.concat((dataset_train_a['Close'], dataset_test['Close']), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(60, 133):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "y_test = sc.inverse_transform(y_test)\n",
    "\n",
    "\n",
    "\n",
    "print('p',predicted_stock_price[0:5])\n",
    "print('r',y_test[0:5])\n",
    "\n",
    "predicted_stock_price=predicted_stock_price[0:60]\n",
    "y_test=y_test[0:60]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the results\n",
    "width = 15\n",
    "height = 10\n",
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "\n",
    "plt.plot(y_test, color = 'red', label = 'Real Nifty  Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Nifty Stock Price')\n",
    "plt.title('Nifty Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Nifty Stock Price')\n",
    "plt.legend()\n",
    "plt.grid(color='b', linestyle='--', linewidth=1)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Score:\", regressor.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsepickel1 = open(\"nsepickel1\",'wb')\n",
    "pickle.dump(regressor , nsepickel1)\n",
    "nsepickel1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
